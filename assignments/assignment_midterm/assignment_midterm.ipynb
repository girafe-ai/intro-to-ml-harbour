{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Midterm test and practice session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Questions.\n",
    "Please, answer the following questions briefly. Two or three sentences with main idea would be enough.\n",
    "\n",
    "Do not use external resourses in this part, please. Answer with you own words. If you forgot something, don't worry, we will discuss it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0. \n",
    "Please, formulate the supervised learning problem statement.\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.\n",
    "\n",
    "What are regression and classification problems. Whatâ€™s the difference?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.\n",
    "Write down the linear model for regression problem in matrix notation. What is Mean Squared Error (MSE) loss function? How can it be expressed?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.\n",
    "What is the gradient of a function? How is it being used in optimization?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.\n",
    "Write down gradient descent step for linear model and MSE for one-dimensional case.\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.\n",
    "What is validation process? And what is cross-validation process?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.\n",
    "What is regularization? How does L1 regularization differ from L2 for linear models?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.\n",
    "What are precision and recall metrics?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8.\n",
    "What is bagging? What is the main idea beneath it?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9.\n",
    "What is Random Forest? How is it different from Gradient Boosting? How prediction are generated from base models in Random Forest and Gradient Boosting?\n",
    "\n",
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Tackling Machine Learning problems in the wild\n",
    "Now you will work with real data in classification problem. Your goal it to solve (with some quality) and make some conclusions. It's quite similar to the `assignment_2`. \n",
    "\n",
    "You may use external resources here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.0 Reading the data\n",
    "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, uncomment the following lines\n",
    "\n",
    "# !wget https://github.com/girafe-ai/intro-to-ml-harbour/raw/master/assignments/assignment_midterm/car_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 19) (846,)\n",
      "(549, 19) (549,) (297, 19) (297,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>85</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>139</td>\n",
       "      <td>173</td>\n",
       "      <td>330</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>184</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>84</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>122</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>123</td>\n",
       "      <td>135</td>\n",
       "      <td>196</td>\n",
       "      <td>128</td>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>101</td>\n",
       "      <td>53</td>\n",
       "      <td>103</td>\n",
       "      <td>203</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>195</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>571</td>\n",
       "      <td>210</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>309</td>\n",
       "      <td>109</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>215</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>205</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>222</td>\n",
       "      <td>624</td>\n",
       "      <td>168</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>195</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181</td>\n",
       "      <td>78</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>116</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>55</td>\n",
       "      <td>17</td>\n",
       "      <td>124</td>\n",
       "      <td>141</td>\n",
       "      <td>221</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>178</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>672</td>\n",
       "      <td>97</td>\n",
       "      <td>47</td>\n",
       "      <td>88</td>\n",
       "      <td>183</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>197</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>148</td>\n",
       "      <td>214</td>\n",
       "      <td>596</td>\n",
       "      <td>201</td>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>45</td>\n",
       "      <td>66</td>\n",
       "      <td>154</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>145</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>144</td>\n",
       "      <td>168</td>\n",
       "      <td>312</td>\n",
       "      <td>177</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>184</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250</td>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>66</td>\n",
       "      <td>126</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>133</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>140</td>\n",
       "      <td>158</td>\n",
       "      <td>253</td>\n",
       "      <td>140</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>184</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>236</td>\n",
       "      <td>96</td>\n",
       "      <td>37</td>\n",
       "      <td>74</td>\n",
       "      <td>199</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>188</td>\n",
       "      <td>419</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>196</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>364</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>77</td>\n",
       "      <td>153</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>154</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>145</td>\n",
       "      <td>181</td>\n",
       "      <td>350</td>\n",
       "      <td>172</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>808</td>\n",
       "      <td>83</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>139</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>146</td>\n",
       "      <td>172</td>\n",
       "      <td>336</td>\n",
       "      <td>183</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>232</td>\n",
       "      <td>81</td>\n",
       "      <td>44</td>\n",
       "      <td>68</td>\n",
       "      <td>120</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>333</td>\n",
       "      <td>178</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>179</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>144</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>80</td>\n",
       "      <td>186</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>164</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>145</td>\n",
       "      <td>188</td>\n",
       "      <td>406</td>\n",
       "      <td>178</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>199</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>217</td>\n",
       "      <td>104</td>\n",
       "      <td>57</td>\n",
       "      <td>103</td>\n",
       "      <td>216</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>219</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>176</td>\n",
       "      <td>228</td>\n",
       "      <td>708</td>\n",
       "      <td>219</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>629</td>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>144</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>131</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>142</td>\n",
       "      <td>154</td>\n",
       "      <td>259</td>\n",
       "      <td>162</td>\n",
       "      <td>65</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n",
       "0   127   85  41   66  155  65  22  149  45  19  139  173  330  155  75   6   \n",
       "1   183   84  35   53  122  57   4  116  59  17  123  135  196  128  76  10   \n",
       "2    75  101  53  103  203  63   9  195  34  22  162  210  571  210  68   5   \n",
       "3   309  109  48  107  215  62  10  205  32  23  158  222  624  168  65   9   \n",
       "4   181   78  36   60  116  56   6  123  55  17  124  141  221  121  78   3   \n",
       "5   672   97  47   88  183  60   7  197  33  23  148  214  596  201  74   8   \n",
       "6    94   84  45   66  154  65   6  145  46  19  144  168  312  177  73   2   \n",
       "7   250   95  38   66  126  52   8  133  52  18  140  158  253  140  78  11   \n",
       "8   236   96  37   74  199  74   5  165  39  20  128  188  419  136  72   1   \n",
       "9   364   87  45   77  153  59   7  154  44  19  145  181  350  172  75  15   \n",
       "10  808   83  46   68  139  59   6  150  44  19  146  172  336  183  74   5   \n",
       "11  232   81  44   68  120  53   6  151  45  19  147  170  333  178  86   4   \n",
       "12  144   95  45   80  186  62   7  164  40  20  145  188  406  178  65  11   \n",
       "13  217  104  57  103  216  69  11  219  30  25  176  228  708  219  73   4   \n",
       "14  629   90  42   63  144  59   7  131  50  18  142  154  259  162  65  15   \n",
       "\n",
       "    16   17   18  \n",
       "0   16  184  191  \n",
       "1   27  183  190  \n",
       "2    5  191  198  \n",
       "3   32  195  206  \n",
       "4   16  178  185  \n",
       "5    0  192  191  \n",
       "6    3  184  188  \n",
       "7    8  184  183  \n",
       "8    3  196  200  \n",
       "9   14  184  189  \n",
       "10   3  185  191  \n",
       "11   5  179  183  \n",
       "12  18  199  204  \n",
       "13   3  186  196  \n",
       "14   3  197  204  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Methods `describe` and `info` deliver some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>419.785064</td>\n",
       "      <td>93.400729</td>\n",
       "      <td>44.480874</td>\n",
       "      <td>81.551913</td>\n",
       "      <td>168.313297</td>\n",
       "      <td>61.730419</td>\n",
       "      <td>8.608379</td>\n",
       "      <td>167.125683</td>\n",
       "      <td>41.327869</td>\n",
       "      <td>20.453552</td>\n",
       "      <td>147.145719</td>\n",
       "      <td>187.408015</td>\n",
       "      <td>431.249545</td>\n",
       "      <td>172.661202</td>\n",
       "      <td>72.326047</td>\n",
       "      <td>6.224044</td>\n",
       "      <td>12.726776</td>\n",
       "      <td>189.169399</td>\n",
       "      <td>195.914390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>244.313766</td>\n",
       "      <td>8.031625</td>\n",
       "      <td>6.149454</td>\n",
       "      <td>15.702513</td>\n",
       "      <td>33.467058</td>\n",
       "      <td>8.687404</td>\n",
       "      <td>5.118808</td>\n",
       "      <td>32.779131</td>\n",
       "      <td>7.818071</td>\n",
       "      <td>2.553824</td>\n",
       "      <td>14.549459</td>\n",
       "      <td>31.337887</td>\n",
       "      <td>173.640290</td>\n",
       "      <td>32.354080</td>\n",
       "      <td>7.913612</td>\n",
       "      <td>4.807886</td>\n",
       "      <td>9.243761</td>\n",
       "      <td>6.193540</td>\n",
       "      <td>7.416811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>409.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>635.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>845.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>1018.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   419.785064   93.400729   44.480874   81.551913  168.313297   61.730419   \n",
       "std    244.313766    8.031625    6.149454   15.702513   33.467058    8.687404   \n",
       "min      4.000000   73.000000   33.000000   40.000000  104.000000   47.000000   \n",
       "25%    212.000000   87.000000   39.000000   70.000000  141.000000   57.000000   \n",
       "50%    409.000000   93.000000   44.000000   79.000000  167.000000   61.000000   \n",
       "75%    635.000000   99.000000   49.000000   96.000000  194.000000   65.000000   \n",
       "max    845.000000  116.000000   58.000000  112.000000  333.000000  138.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean     8.608379  167.125683   41.327869   20.453552  147.145719  187.408015   \n",
       "std      5.118808   32.779131    7.818071    2.553824   14.549459   31.337887   \n",
       "min      2.000000  112.000000   26.000000   17.000000  118.000000  130.000000   \n",
       "25%      6.000000  144.000000   34.000000   19.000000  136.000000  166.000000   \n",
       "50%      8.000000  157.000000   43.000000   20.000000  145.000000  179.000000   \n",
       "75%     10.000000  192.000000   46.000000   22.000000  158.000000  214.000000   \n",
       "max     52.000000  265.000000   61.000000   29.000000  188.000000  320.000000   \n",
       "\n",
       "                12          13          14          15          16  \\\n",
       "count   549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean    431.249545  172.661202   72.326047    6.224044   12.726776   \n",
       "std     173.640290   32.354080    7.913612    4.807886    9.243761   \n",
       "min     184.000000  112.000000   60.000000    0.000000    0.000000   \n",
       "25%     312.000000  147.000000   67.000000    2.000000    5.000000   \n",
       "50%     362.000000  172.000000   71.000000    5.000000   11.000000   \n",
       "75%     563.000000  195.000000   75.000000    9.000000   19.000000   \n",
       "max    1018.000000  264.000000  135.000000   21.000000   41.000000   \n",
       "\n",
       "               17          18  \n",
       "count  549.000000  549.000000  \n",
       "mean   189.169399  195.914390  \n",
       "std      6.193540    7.416811  \n",
       "min    176.000000  181.000000  \n",
       "25%    185.000000  191.000000  \n",
       "50%    189.000000  197.000000  \n",
       "75%    194.000000  201.000000  \n",
       "max    204.000000  211.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bus', 'opel', 'saab', 'van'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549 entries, 0 to 548\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       549 non-null    int32\n",
      " 1   1       549 non-null    int32\n",
      " 2   2       549 non-null    int32\n",
      " 3   3       549 non-null    int32\n",
      " 4   4       549 non-null    int32\n",
      " 5   5       549 non-null    int32\n",
      " 6   6       549 non-null    int32\n",
      " 7   7       549 non-null    int32\n",
      " 8   8       549 non-null    int32\n",
      " 9   9       549 non-null    int32\n",
      " 10  10      549 non-null    int32\n",
      " 11  11      549 non-null    int32\n",
      " 12  12      549 non-null    int32\n",
      " 13  13      549 non-null    int32\n",
      " 14  14      549 non-null    int32\n",
      " 15  15      549 non-null    int32\n",
      " 16  16      549 non-null    int32\n",
      " 17  17      549 non-null    int32\n",
      " 18  18      549 non-null    int32\n",
      "dtypes: int32(19)\n",
      "memory usage: 40.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Data preprocessing\n",
    "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Logistic regression\n",
    "* Find the optimal hyperparameters for logistic regression using cross-validation (e.g. `GridSearchCV`). You can vary only a parameter for `l2` regularization (e.g 5 different values).\n",
    "\n",
    "* Then build a ROC curve for this classifier (`sklearn.metrics.roc_curve`). Estimate the model quality with appropriate metrics (which will you use?)\n",
    "\n",
    "_Note: be careful with preprocessing (like scaling) to avoid data leaks._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fbf16c64076e139",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. Decision tree\n",
    "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation (again, checking 5 variants would be fine).\n",
    "\n",
    "* Measure the model quality using the same metrics you used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-748ed20b51c67fab",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-241b7691ab44cbfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.4. Random Forest\n",
    "Now we will work with the Random Forest (its `sklearn` implementation).\n",
    "\n",
    "* Vary the number of trees (from 5 to 50 with step 5) and build the plot in axes \"model accuracy\" - \"number of trees\".\n",
    "\n",
    "* What is the optimal number of trees you've got?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888755d0f3d91620",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.5. Bonus part: \"learning curve\"\n",
    "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
    "\n",
    "* Build a plot of accuracy and f1-score (on `test` part) varying the `train` dataset size (so the axes will be metric - dataset size.\n",
    "\n",
    "* Analyse the final plot. Can you make any conlusions using it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e39bc7e7dff61ff9",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
