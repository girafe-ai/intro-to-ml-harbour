{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterization methods\n",
    "<h3> Plan </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pylab\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "from IPython.display import Image, SVG\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Questions **\n",
    "* What is clusterization?\n",
    "* What main steps are in K-Means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means demo\n",
    "<a href='https://www.naftaliharris.com/blog/visualizing-k-means-clustering/'> k-means </a>\n",
    "\n",
    "## DBSCAN demo\n",
    "<a href='https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/'> DBSCAN </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "<h1 align=\"center\"> K-Means </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** k-means steps: **\n",
    " - 1. update clusters (reassign objects to clusters):\n",
    "     ## $$ y_i := \\arg\\min\\limits_{y\\in Y} \\rho (x_i ; \\mu_y),~~i = 1,\\dots,\\ell;$$\n",
    " - 2: update clusters weights\n",
    "##    $$ \\mu_{yj} := \\frac{\\sum_{i=1}^\\ell [y_i = y]\\cdot f_j(x_i)} {\\sum_{i=1}^\\ell[y_i = y]}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    def __init__(self, K, X=None, N=0):\n",
    "        '''\n",
    "        K - number of clusters\n",
    "        X - dataset (if X is None then X is generated from gauss distribution)\n",
    "        N - a number of samples to generate if X is None\n",
    "        '''\n",
    "        self.K = K\n",
    "        if X is None:\n",
    "            if N == 0:\n",
    "                raise Exception(\"If no data is provided, \\\n",
    "                                 a parameter N (number of points) is needed\")\n",
    "            else:\n",
    "                self.N = N\n",
    "                self.X = self._init_board_gauss(N, K)\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.N = len(X)\n",
    "            \n",
    "        # initialization            \n",
    "        self.mu = None # a list of centers of clusters\n",
    "        self.clusters = None # labels of samples\n",
    "        self.method = None # method for sampling initial centers of clusters\n",
    " \n",
    "    def _init_board_gauss(self, N, k):\n",
    "        '''\n",
    "        N - a number of samples to generate\n",
    "        k - a number of clusters\n",
    "        '''\n",
    "        n = float(N)/k\n",
    "        X = []\n",
    "        for i in range(k):\n",
    "            c = (random.uniform(-1,1), random.uniform(-1,1))\n",
    "            s = random.uniform(0.05,0.15)\n",
    "            x = []\n",
    "            while len(x) < n:\n",
    "                a,b = np.array([np.random.normal(c[0],s),np.random.normal(c[1],s)])\n",
    "                # Continue drawing points from the distribution in the range [-1,1]\n",
    "                if abs(a) and abs(b)<1:\n",
    "                    x.append([a,b])\n",
    "            X.extend(x)\n",
    "        X = np.array(X)[:N]\n",
    "        return X\n",
    " \n",
    "    def plot_board(self, fig_size=(10,7) ):\n",
    "        '''\n",
    "        '''\n",
    "        X = self.X\n",
    "        fig = plt.figure(figsize = fig_size)\n",
    "        plt.xlim(-1,1)\n",
    "        plt.ylim(-1,1)\n",
    "        if self.mu and self.clusters:\n",
    "            mu = self.mu\n",
    "            clus = self.clusters\n",
    "#             print(clus)\n",
    "            K = self.K\n",
    "            for m, clu in clus.items():\n",
    "                cmap = plt.cm.get_cmap(\"Spectral\")\n",
    "                cs = cmap(1.*m/self.K)\n",
    "                plt.plot(mu[m][0], mu[m][1], 'o', marker='*', \\\n",
    "                         markersize=20, color=cs)\n",
    "#                 print(zip(clus[m]))\n",
    "                plt.plot([x[0] for x in clus[m]], [x[1] for x in clus[m]], '.', \\\n",
    "                         markersize=8, color=cs, alpha=0.5)\n",
    "        else:\n",
    "            plt.plot(X[:,0], X[:,1], '.', alpha=0.5)\n",
    "        if self.method == '++':\n",
    "            tit = 'K-means++'\n",
    "        else:\n",
    "            tit = 'K-means with random initialization'\n",
    "        pars = 'N=%s, K=%s' % (str(self.N), str(self.K))\n",
    "        plt.title('\\n'.join([pars, tit]), fontsize=16)\n",
    "        plt.savefig('kpp_N%s_K%s.png' % (str(self.N), str(self.K)), \\\n",
    "                    bbox_inches='tight', dpi=200)\n",
    " \n",
    "\n",
    "    def _reevaluate_centers(self):\n",
    "        '''\n",
    "        Maximization step in Kmeans\n",
    "        '''\n",
    "        clusters = self.clusters\n",
    "        newmu = []\n",
    "        keys = sorted(self.clusters.keys())\n",
    "        for k in keys:\n",
    "            newmu.append(np.mean(clusters[k], axis = 0))\n",
    "        self.mu = newmu\n",
    "        \n",
    "    def _cluster_points(self):\n",
    "        '''\n",
    "        expectation step in Kmeans \n",
    "        '''\n",
    "        mu = self.mu\n",
    "        clusters  = {}\n",
    "        for x in self.X:\n",
    "            bestmukey = # YOUR CODE!!!For x find index of the nearest cluster for it (use np.linalg.norm)!!!\n",
    "            try:\n",
    "                clusters[bestmukey].append(# YOUR CODE!!!Add x to the find cluster's list of elements!!!)\n",
    "            except KeyError:\n",
    "                clusters[bestmukey] = [x]\n",
    "                                           \n",
    "        if len(clusters) < self.K:\n",
    "            for k in range(len(self.K)):\n",
    "                if k not in clusters.keys():\n",
    "                    clusters[k] = mu[k] # Not update cluster\n",
    "                                           \n",
    "        self.clusters = clusters\n",
    " \n",
    "\n",
    "    def find_centers(self, method='random'):\n",
    "        self.method = method\n",
    "        X = self.X\n",
    "        K = self.K\n",
    "        #print(X)\n",
    "        self.oldmu = random.sample(list(X), K)\n",
    "        if method != '++':\n",
    "            # Initialize to K random centers\n",
    "            self.mu = random.sample(list(X), K)\n",
    "        while not self._has_converged():\n",
    "            self.oldmu = self.mu # remember previous cluster centers\n",
    "            # Assign all points in X to clusters\n",
    "            self._cluster_points()\n",
    "            # Reevaluate centers\n",
    "            self._reevaluate_centers()\n",
    "                                           \n",
    "    def _has_converged(self):\n",
    "        '''\n",
    "        condition of convergence of cluster points\n",
    "        '''\n",
    "        K = len(self.oldmu)\n",
    "        return(# YOUR CODE!!!Check that our optimization has converged (use self.oldmu)!!!  \n",
    "            and len(set([tuple(a) for a in self.mu])) == K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(K=3, N=200)\n",
    "kmeans.find_centers()\n",
    "kmeans.plot_board(fig_size=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans.find_centers()\n",
    "kmeans.plot_board(fig_size=(15,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve to Kmeans++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPlusPlus(KMeans):\n",
    "    def _dist_from_centers(self):\n",
    "        cent = self.mu\n",
    "        X = self.X\n",
    "        D2 = np.array([min([np.linalg.norm(x-c)**2 for c in cent]) for x in X])\n",
    "        self.D2 = D2\n",
    " \n",
    "    def _choose_next_center(self):\n",
    "        self.probs = self.D2/self.D2.sum()\n",
    "        self.cumprobs = self.probs.cumsum()\n",
    "        r = (random.random()+1.0)/2\n",
    "        ind = np.where(self.cumprobs >= r)[0][0]\n",
    "        return(self.X[ind])\n",
    " \n",
    "    def init_centers(self):\n",
    "        self.mu = random.sample(list(self.X), 1)\n",
    "        while len(self.mu) < self.K:\n",
    "            self._dist_from_centers()\n",
    "            self.mu.append(self._choose_next_center())\n",
    " \n",
    "    def plot_init_centers(self, fig_size = (10,7)):\n",
    "        X = self.X\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        plt.xlim(-1,1)\n",
    "        plt.ylim(-1,1)\n",
    "        plt.plot(X[:,0], X[:,1], '.', alpha=0.5)\n",
    "        plt.plot([x[0] for x in self.mu], [x[1] for x in self.mu], 'ro')\n",
    "        plt.savefig('kpp_init_N%s_K%s.png' % (str(self.N),str(self.K)), \\\n",
    "                    bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kplusplus = KPlusPlus(K=5, N=400)\n",
    "kplusplus.plot_board(fig_size = (15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization\n",
    "kplusplus.find_centers(method='random')\n",
    "kplusplus.plot_board(fig_size = (15,3))\n",
    "# k-means++ initialization\n",
    "kplusplus.init_centers()\n",
    "kplusplus.plot_init_centers(fig_size=(10,3))\n",
    "kplusplus.find_centers(method='++')\n",
    "kplusplus.plot_board(fig_size = (15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "<h1 align=\"center\">Text clusterization</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = fetch_20newsgroups(subset='train')\n",
    "print (train_all.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dataset = fetch_20newsgroups(\n",
    "    subset='train', \n",
    "    categories=['comp.sys.mac.hardware', 'soc.religion.christian', 'rec.sport.hockey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (simple_dataset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (simple_dataset.data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (simple_dataset.data[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(simple_dataset.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=500, min_df=10)\n",
    "matrix = vectorizer.fit_transform(simple_dataset.data)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AgglomerativeClustering, Neighbour joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster.hierarchical import AgglomerativeClustering\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=3, affinity='cosine', linkage='complete')\n",
    "preds = model.fit_predict(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(list(preds)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[877]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dataset.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessement\n",
    "mapping = {2 : 1, 1: 2, 0: 0}\n",
    "mapped_preds = [mapping[pred] for pred in preds]\n",
    "# print (float(sum(mapped_preds != simple_dataset.target)) / len(simple_dataset.target))\n",
    "print(acc(mapped_preds, simple_dataset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def validate_with_mappings(preds, target):\n",
    "    permutations = itertools.permutations([0, 1, 2])\n",
    "    for a, b, c in permutations:\n",
    "        mapping = {2 : a, 1: b, 0: c}\n",
    "        mapped_preds = [mapping[pred] for pred in preds]\n",
    "#         print (float(sum(mapped_preds != target)) / len(target))\n",
    "        print(acc(mapped_preds, target))\n",
    "validate_with_mappings(preds, simple_dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=1)\n",
    "preds = model.fit_predict(matrix.toarray())\n",
    "print (preds)\n",
    "print (simple_dataset.target)\n",
    "validate_with_mappings(preds, simple_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Linear Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "print (cross_val_score(clf, matrix, simple_dataset.target).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: ** Very big quality of K-Means, nearly as supervised algorithm, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteasy_dataset = fetch_20newsgroups(\n",
    "    subset='train', \n",
    "    categories=['comp.sys.mac.hardware', 'comp.os.ms-windows.misc', 'comp.graphics'])\n",
    "matrix = vectorizer.fit_transform(noteasy_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3, random_state=1)\n",
    "preds = model.fit_predict(matrix.toarray())\n",
    "print (preds)\n",
    "print (noteasy_dataset.target)\n",
    "validate_with_mappings(preds, noteasy_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "print (cross_val_score(clf, matrix, noteasy_dataset.target).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD + KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "svd = TruncatedSVD(n_components=1000, random_state=123)\n",
    "features = svd.fit_transform(matrix)\n",
    "preds = model.fit_predict(features)\n",
    "validate_with_mappings(preds, noteasy_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "svd = TruncatedSVD(n_components=200, random_state=321)\n",
    "features = svd.fit_transform(matrix)\n",
    "preds = model.fit_predict(features)\n",
    "validate_with_mappings(preds, noteasy_dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality of clusterization\n",
    "--------\n",
    "\n",
    "### Homogeneity:  each cluster contains only members of a single class\n",
    "\n",
    "### Completeness: all members of a given class are assigned to the same cluster\n",
    "\n",
    "### V-measure:\n",
    "### $$v = 2 \\cdot \\frac{(homogeneity \\cdot completeness)}{ (homogeneity + completeness)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import homogeneity_score, completeness_score,v_measure_score \n",
    "\n",
    "print(completeness_score(noteasy_dataset.target, preds))\n",
    "print(homogeneity_score(noteasy_dataset.target, preds))\n",
    "print(v_measure_score(noteasy_dataset.target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Good results for both text datasets\n",
    "2. On easy data clusterization methods work well"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
