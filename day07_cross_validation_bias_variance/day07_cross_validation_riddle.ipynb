{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9UXfYah4Dsn"
   },
   "source": [
    "*Credits: this notebook origin (shared under MIT license) belongs to [ML course at ICL](https://github.com/yandexdataschool/MLatImperial2020) held by Yandex School of Data Analysis. Special thanks to the course team for making it available online.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij_zY4soDF2Z"
   },
   "source": [
    "## day07: Cross-validation riddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUCsY5OlDJPl"
   },
   "source": [
    "Here's a small example of cross-validation done wrongly. Can you spot the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSUzkXsC-R4H"
   },
   "outputs": [],
   "source": [
    "# Some imports...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyDp3Xc_DaDM"
   },
   "source": [
    "**Plan:**\n",
    "\n",
    "- Let's create a binary classification dataset where targets are completely independent from the features\n",
    "  - *(i.e. no model could ever predict them well)*\n",
    "- We'll do some simple feature selection\n",
    "- And cross-validate a model on this data\n",
    "\n",
    "**Q:** what accuracy do we expect (classes are even)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHx51DKP8Rcf"
   },
   "source": [
    "We'll start from writing a class to select the best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRNmKZJJ8W7x"
   },
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    def __init__(self, num_features):\n",
    "        self.n = num_features # number of best features to select\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Select features that describe the targets best, i.e. have\n",
    "        # highest correlation with them:\n",
    "        covariance = ((X - X.mean(axis=0)) * (y[:,np.newaxis] - y.mean())).mean(axis=0)\n",
    "        self.best_feature_ids = np.argsort(np.abs(covariance))[-self.n:]\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:,self.best_feature_ids]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6mu9gHgNBk_V",
    "outputId": "020bdc20-04e3-45c3-a3a7-a4c2cf9139e5"
   },
   "outputs": [],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "\n",
    "# Dataset generation\n",
    "X = np.random.normal(size=(N, num_features_total))\n",
    "y = np.random.randint(2, size=N)\n",
    "\n",
    "# Feature selection:\n",
    "X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
    "\n",
    "# Simple classification model\n",
    "model = LinearSVC()\n",
    "\n",
    "# Estimatin accuracy using cross-validation:\n",
    "cv_score = cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "print(f\"CV score is {cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afadN3ZVFKjF"
   },
   "source": [
    "What's going on?! Why accuracy is so high?\n",
    "\n",
    "Maybe it just happened by chance? Let's repeat this experiment many times and histogram the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "QDbOMXnuC6uw",
    "outputId": "597d41e7-482b-4f6a-8565-316644c1b04e"
   },
   "outputs": [],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "def experiment():\n",
    "    # Dataset generation\n",
    "    X = np.random.normal(size=(N, num_features_total))\n",
    "    y = np.random.randint(2, size=N)\n",
    "\n",
    "    # Feature selection:\n",
    "    X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
    "\n",
    "    # Simple classification model\n",
    "    model = LinearSVC()\n",
    "\n",
    "    # Estimatin accuracy using cross-validation:\n",
    "    return cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "\n",
    "results = [experiment() for _ in range(100)]\n",
    "plt.hist(results, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bLaEypoF5pb"
   },
   "source": [
    "Can you explain and fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGshBeG_4Dsy"
   },
   "outputs": [],
   "source": [
    "# It's dangerous to go alone. Take this!\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gf9R3sPw4Dsy"
   },
   "outputs": [],
   "source": [
    "# YOUR BEAUTIFUL FIX HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day07: Cross-validation riddle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
